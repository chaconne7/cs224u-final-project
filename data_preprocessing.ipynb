{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from constants import *\n",
    "import json \n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data'\n",
    "# source_path = data_path + '/CLOTH'\n",
    "# data_types = ['/high', '/middle']\n",
    "\n",
    "# data_splits = ['/train', '/test', '/valid']\n",
    "# dest_path = data_path + '/cleaned'\n",
    "# train_dest_path = dest_path + '/train'\n",
    "# test_dest_path = dest_path + '/test'\n",
    "# valid_dst_path = dest_path + '/valid'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_indices(answers): \n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "    return [mapping[entry] for entry in answers]\n",
    "    \n",
    "def fill_in_extra_blanks(sentence, answer_indices, options, blank_index): \n",
    "    index = sentence.find('_');\n",
    "    num_blanks = sentence.count('_')\n",
    "    replacements = []\n",
    "    for i in range(num_blanks): \n",
    "        word = options[blank_index + i][answer_indices[blank_index + i]] if i > 0 else '[MASK]'\n",
    "        replacements.append(word)\n",
    "        \n",
    "    def replace_with(_):\n",
    "        \"\"\"Returns first value of substr and removes it.\"\"\"\n",
    "        return replacements.pop(0)\n",
    "    \n",
    "    sentence = re.sub(\"_\",replace_with,sentence)\n",
    "\n",
    "    return sentence, num_blanks\n",
    "    \n",
    "def create_training_example(sentence, options_for_sentence, correct_answer): \n",
    "    example = {}\n",
    "    sentence = \" \".join(sentence.split())\n",
    "    example['sentence'] = sentence \n",
    "    example['answer'] = correct_answer \n",
    "    example['candidates'] = options_for_sentence\n",
    "    return example\n",
    "    \n",
    "    \n",
    "def create_processed_file(data_split, data_type, source_filename): \n",
    "    source_filepath = SOURCE_PATH + data_split + data_type + source_filename \n",
    "    dest_filename = source_filename[:-4] + 'pickle'\n",
    "    dest_filepath = DEST_PATH + data_split + data_type + dest_filename\n",
    "    with open(source_filepath, 'r') as json_file, open(dest_filepath, \"wb\") as pickle_file: \n",
    "        examples = []\n",
    "        data = json.load(json_file)\n",
    "        answers = data['answers']\n",
    "        answer_indices = get_answer_indices(answers)\n",
    "        options = data['options']\n",
    "        article = data['article']\n",
    "        blank_index = 0\n",
    "        for sentence in nltk.sent_tokenize(article): \n",
    "            if blank_index >= len(answer_indices): \n",
    "                break\n",
    "            sentence, num_blanks = fill_in_extra_blanks(sentence, answer_indices, options, blank_index)\n",
    "            if num_blanks > 0: \n",
    "                options_for_sentence = options[blank_index]\n",
    "                correct_answer = options_for_sentence[answer_indices[blank_index]]\n",
    "                example = create_training_example(sentence, options_for_sentence, correct_answer)\n",
    "                examples.append(example)\n",
    "            blank_index += num_blanks \n",
    "        pickle.dump(examples, pickle_file)\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_files(): \n",
    "    for data_split in DATA_SPLITS: \n",
    "        for data_type in DATA_TYPES:\n",
    "            path = SOURCE_PATH + data_split + data_type \n",
    "            filenames = os.listdir(path)\n",
    "            for filename in filenames: \n",
    "                filename = '/' + filename\n",
    "                path = path + filename\n",
    "                create_processed_file(data_split, data_type, filename)\n",
    "                return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentence': 'A teacher shows three toys to a student .Then she asks the student to find out the [MASK] .', 'answer': 'differences', 'candidates': ['differences', 'usage', 'weaknesses', 'categories']}, {'sentence': 'All the three toys seem to be [MASK] in their shape, size and material.', 'answer': 'identical', 'candidates': ['excellent', 'simple', 'identical', 'difficult']}, {'sentence': 'After careful [MASK] , the student sees holes in the toys.', 'answer': 'observation', 'candidates': ['imagination', 'discussion', 'observation', 'selection']}, {'sentence': 'The first toy has holes in the [MASK] .', 'answer': 'ears', 'candidates': ['mouth', 'nose', 'eyes', 'ears']}, {'sentence': 'Then with the [MASK] of a needle, which is put into the holes in one of the ears of the three toys, the student realizes the importance of the company of the people who are trustworthy .', 'answer': 'help', 'candidates': ['invention', 'help', 'discovery', 'company']}, {'sentence': 'The first toy represents those people around you who give a(n) [MASK] that they are listening to you ,all your things and care for you.', 'answer': 'impression', 'candidates': ['impression', 'encouragement', 'privilege', 'assumption']}, {'sentence': 'But they just [MASK] to do so.', 'answer': 'pretend', 'candidates': ['agree', 'pretend', 'manage', 'happen']}, {'sentence': 'After listening, [MASK] the needle would come out from the other ear of the first toy, the things you said to them are gone .', 'answer': 'as', 'candidates': ['until', 'when', 'as', 'if']}, {'sentence': 'So be [MASK] while you are speaking to this type of people around you, who never care for you.', 'answer': 'careful', 'candidates': ['careful', 'cheerful', 'serious', 'strict']}, {'sentence': 'The second toy represents those people who listen to you and all your things and it seems that you [MASK] a lot to them.', 'answer': 'mean', 'candidates': ['devote', 'mean', 'teach', 'leave']}, {'sentence': 'The needle would not come out in the third toy, which represents those people who will keep the [MASK] you have in them.', 'answer': 'trust', 'candidates': ['confidence', 'trust', 'ambition', 'patience']}, {'sentence': 'People, who listen to what you tell them, are not [MASK] the ones you can count on when you need them the most.', 'answer': 'always', 'candidates': ['just', 'nearly', 'always', 'already']}]\n"
     ]
    }
   ],
   "source": [
    "with open('data/cleaned/test/high/high4063.pickle', 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
